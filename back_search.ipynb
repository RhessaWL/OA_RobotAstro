{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install BeautifulSoup4\n",
    "#%pip install requests\n",
    "#%pip install gensim==3.6.0\n",
    "#%pip install nltk\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#%pip install xlrd\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reads headlines.txt file into list \n",
    "def read_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        each_line = f.readlines()\n",
    "        headlines = []\n",
    "        for word in each_line:\n",
    "            if word.isalpha():\n",
    "                each_line = each_line.replace(word, word.lower())       \n",
    "        for line in each_line:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                headlines.append(line)\n",
    "        return headlines\n",
    "    \n",
    "# Reads populat_topics.txt file and returns list\n",
    "def read_file_word(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        each_line = f.read().split()\n",
    "        return each_line\n",
    "\n",
    "# Read links file into list    \n",
    "def read_links(filename):\n",
    "    with open(filename, 'r') as l:\n",
    "        links = [line.strip() for line in l]\n",
    "        return links\n",
    "    \n",
    "# Returns nouns from string\n",
    "def return_noun(line):\n",
    "    # function to test if something is a noun\n",
    "    is_noun = lambda pos: pos[:2] == 'NN'\n",
    "    # do the nlp stuff\n",
    "    tokenized = nltk.word_tokenize(line)\n",
    "    nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if is_noun(pos)]\n",
    "    return nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = read_file_word('data/popular_topics.txt')\n",
    "headlines = read_file('data/headlines.txt')\n",
    "links = read_links('data/links.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets the headlines that have the top words\n",
    "def get_headlines(words, headlines):\n",
    "    popular_headlines = []\n",
    "    for word in words:\n",
    "        for headline in headlines:\n",
    "            if word in headline.split():\n",
    "                popular_headlines.append(headline)\n",
    "            else:\n",
    "                continue\n",
    "    return popular_headlines\n",
    "\n",
    "# Find link for given headline and add it to list_links with headline\n",
    "def get_links(popular_headlines, headlines, links):\n",
    "    \n",
    "    list_links = []\n",
    "    for x in popular_headlines:\n",
    "        if x in headlines:\n",
    "            index = headlines.index(x)\n",
    "            link = links[index]\n",
    "            list_links.append(link)\n",
    "        else:\n",
    "            print(\"Headline not found.\")\n",
    "    return list_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_word_lists():\n",
    "    # Read the NGC Excel file into a dataframe\n",
    "    df1 = pd.read_excel('data/NGC.xlsx', sheet_name='NGC')\n",
    "\n",
    "    # Read the Messier Excel file into a dataframe\n",
    "    df2 = pd.read_excel('data/mesr-mas.xls', sheet_name='Messier Objects', skiprows = 8, nrows=110, usecols=range(2))\n",
    "\n",
    "    # Create lists for each Messier and NGC objects\n",
    "    messier1 = df2.iloc[:,0].tolist()\n",
    "    NGC2 = df2.iloc[:,1].dropna().tolist()\n",
    "    NGC1 = df1.iloc[:,24].dropna().tolist()\n",
    "\n",
    "    # Combine two NGC to find missing elements\n",
    "    NGC_str = list(set(NGC1).union(set(NGC2)))\n",
    "\n",
    "    # Convert to string plus catalog identifier\n",
    "    messier = ['M' + str(element) for element in messier1]\n",
    "    NGC = ['NGC ' + str(element).rstrip('.0') for element in NGC_str]\n",
    "    d_planets = ['Pluto', 'Ceres', 'Makemake', 'Haumea', 'Eris']\n",
    "    mars_moons = ['Deimos', 'Phobos']\n",
    "    named_jupiter_moons = ['Adrastea', 'Aitne', 'Amalthea', 'Ananke', 'Aoede', 'Arche', 'Autonoe', 'Callirrhoe', 'Callisto', 'Carme', \n",
    "                    'Carpo', 'Chaldene', 'Cyllene', 'Dia', 'Eirene', 'Elara', 'Erinome', 'Ersa', 'Euanthe', 'Eukelade', 'Eupheme', \n",
    "                    'Euporie', 'Europa', 'Eurydome', 'Ganymede', 'Harpalyke', 'Hegemone', 'Helike', 'Hermippe', 'Herse', 'Himalia', \n",
    "                    'Io', 'Iocaste', 'Isonoe', 'Jupiter LI', 'Jupiter LII', 'Kale', 'Kallichore', 'Kalyke', 'Kore', 'Leda', 'Lysithea', \n",
    "                    'Megaclite', 'Metis', 'Mneme', 'Orthosie', 'Pasiphae', 'Pasithee', 'Praxidike', 'Valetudo', 'Sinope', 'Sponde', \n",
    "                    'Taygete', 'Thebe', 'Thelxinoe', 'Themisto', 'Thyone']\n",
    "    named_saturn_moons = ['Aegaeon', 'Aegir', 'Albiorix', 'Anthe', 'Atlas', 'Bebhionn', 'Bergelmir', 'Bestla', 'Calypso', 'Daphnis', \n",
    "                    'Dione', 'Enceladus', 'Epimetheus', 'Erriapus', 'Farbauti', 'Fenrir', 'Fornjot', 'Greip', 'Hati', 'Helene', \n",
    "                    'Hyperion', 'Hyrrokkin', 'Iapetus', 'Ijiraq', 'Janus', 'Jarnsaxa', 'Kari', 'Kiviuq', 'Loge', 'Methone', \n",
    "                    'Mimas', 'Mundilfari', 'Narvi', 'Paaliaq', 'Pallene', 'Pan', 'Pandora', 'Phoebe', 'Polydeuces', 'Prometheus', \n",
    "                    'Rhea', 'Siarnaq', 'Skathi', 'Skoll', 'Surtur', 'Suttungr', 'Tarqeq', 'Tarvos', 'Telesto', 'Tethys', 'Thrymyr', \n",
    "                    'Titan', 'Ymir']\n",
    "    named_uranus_names = ['Ariel', 'Belinda', 'Bianca', 'Caliban', 'Cordelia', 'Cressida', 'Cupid', 'Desdemona', 'Ferdinand', 'Francisco', \n",
    "                'Juliet', 'Mab', 'Margaret', 'Miranda', 'Oberon', 'Ophelia', 'Perdita', 'Portia', 'Prospero', 'Puck', 'Rosalind', \n",
    "                'Setebos', 'Stephano', 'Sycorax', 'Titania', 'Trinculo', 'Umbriel']\n",
    "    named_neptune_moons = ['Despina', 'Galatea', 'Halimede', 'Hippocamp', 'Laomedeia', 'Larissa', 'Naiad', 'Nereid', 'Neso', 'Proteus', \n",
    "                'Psamathe', 'Sao', 'Thalassa', 'Triton']\n",
    "    named_pluto_moons = ['Charon', 'Hydra', 'Kerberos', 'Nix', 'Styx']\n",
    "    exoplanet_names = ['Proxima Centauri b', 'TRAPPIST-1d', 'LHS 1140 b', 'Kepler-438b', 'Kepler-442b', 'Kepler-452b', 'Kepler-1229b', \n",
    "                    'Kepler-62f', 'Kepler-186f', 'Kepler-452b', 'Kepler-1652b', 'Kepler-442b', 'Kepler-1638b', 'Kepler-438b', 'Kepler-1229b', \n",
    "                    'Kepler-1649c', 'Kepler-62f', 'Kepler-186f', 'Kepler-69c', 'Kepler-1649c', 'Kepler-1652b', 'Kepler-1638b', 'Kepler-62e', \n",
    "                    'Kepler-438b', 'Kepler-442b', 'Kepler-452b', 'Kepler-1229b', 'Kepler-442b', 'Kepler-1649c', 'Kepler-1638b', 'Kepler-438b', \n",
    "                    'Kepler-1652b', 'Kepler-62f', 'Kepler-62e', 'Kepler-186f', 'Kepler-438b', 'Kepler-452b', 'Kepler-442b', 'Kepler-1649c', \n",
    "                    'Kepler-62f', 'Kepler-1652b', 'Kepler-1638b', 'Kepler-438b', 'Kepler-62e', 'Kepler-1229b', 'Kepler-186f', 'Kepler-69c', \n",
    "                    'Kepler-1649c', 'Kepler-438b', 'Kepler-442b', 'Kepler-1638b', 'Kepler-1652b', 'Kepler-62f', 'Kepler-62e', 'Kepler-186f', \n",
    "                    'Kepler-1649c', 'Kepler-1229b', 'Kepler-438b', 'Kepler-69c', 'Kepler-442b', 'Kepler-1638b', 'Kepler-452b', 'Kepler-1652b', \n",
    "                    'Kepler-62f', 'Kepler-62e', 'Kepler-186f', 'Kepler-1649c', 'Kepler-438b', 'Kepler-1229b', 'Kepler-1638b', 'Kepler-442b', \n",
    "                    'Kepler-1652b', 'Kepler-452b', 'Kepler-1649c', 'Kepler-62f', 'Kepler-186f', 'Kepler-438b', 'Kepler-62e', 'Kepler-69c', \n",
    "                    'Kepler-442b', 'Kepler-1229b', 'Kepler-1638b', 'Kepler-1652b', 'Kepler-62f', 'Kepler-1649c', 'Kepler-452b', 'Kepler-438b', \n",
    "                    'Kepler-186f', 'Kepler-62e', 'Kepler-442b', 'Kepler-1638b', 'Kepler-1652b', 'Kepler-69c', 'Kepler-1649c', 'Kepler-62f', \n",
    "                    'Kepler-438b', 'Kepler-1229b', 'Kepler-186f', 'Kepler-62e', 'Kepler-452b']\n",
    "    more_exoplanets =  [ 'Proxima Centauri b','TRAPPIST-1b','TRAPPIST-1c','TRAPPIST-1e','TRAPPIST-1f','TRAPPIST-1g','TRAPPIST-1h','Tau Cetie',\n",
    "                        'Tau Cetif','Ross 128b','LHS 1140b', 'Wolf 1061c','Wolf 1061d','Kepler-1649c','Gliese 667Cc','Gliese 667Cf','Gliese 667Ce',\n",
    "                        'HD-40307g','Gliese 163c','Gliese 832c','Gliese 667Cb']\n",
    "    \n",
    "\n",
    "\n",
    "    # Create one total list\n",
    "    total_list = messier+NGC+d_planets+mars_moons+named_uranus_names+named_jupiter_moons+named_neptune_moons+named_pluto_moons+named_saturn_moons+exoplanet_names+more_exoplanets\n",
    "    return total_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summarizes content from links (1m 10s)\n",
    "def summarize_artciles(list_links):\n",
    "    summary_list = []\n",
    "    # Loop through each link\n",
    "    for link in list_links:\n",
    "        \n",
    "        # Download HTML content of link\n",
    "        headers ={'User-Agent': 'Chrome/58.0.3029.110 Safari/537.3'}\n",
    "        response = requests.get(link, headers=headers)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "        # Extract article content\n",
    "        paragraphs = soup.find_all('p')\n",
    "        article_text = '\\n'.join([p.text for p in paragraphs])\n",
    "\n",
    "        # Summarize article content\n",
    "        if (len(summarize(article_text, ratio=0.4, split=True)))==0:\n",
    "            summary = summarize(article_text, ratio=0.4, split=True)\n",
    "            # Append summary\n",
    "            summary_list.append(summary)\n",
    "        else:\n",
    "            summary = summarize(article_text, ratio=0.4, split=True)\n",
    "            # Append summary\n",
    "            summary_list.append(summary)\n",
    "    return summary_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare each summary to the list of Messier objects\n",
    "def object_list(total_list, summary_list):\n",
    "    object_ls = []\n",
    "    for object_name in total_list:\n",
    "        for summary1 in summary_list:\n",
    "            for summary in summary1:\n",
    "                if re.search(r'\\b' + object_name + r'\\b', summary):\n",
    "                    if object_name in object_ls:\n",
    "                        continue\n",
    "                    else:\n",
    "                        object_ls.append(object_name)\n",
    "    return object_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final function, runs full file\n",
    "def run_back_search():\n",
    "    popular_headlines = get_headlines(words, headlines)\n",
    "    list_links = get_links(popular_headlines, headlines, links)\n",
    "    total_list = make_word_lists()\n",
    "    summary_list = summarize_artciles(list_links)\n",
    "    object_ls = object_list(total_list, summary_list)\n",
    "    # Print to new file called 'popular topics'\n",
    "    with open('data/final_objects.txt', 'w') as f:\n",
    "        for items in reversed(object_ls):\n",
    "            f.write(items+ '\\n')\n",
    "    f.close\n",
    "    print(\"Done\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "astrobio",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
