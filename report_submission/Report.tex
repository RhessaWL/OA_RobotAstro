% template.tex
% COMS 4733 course staff, Columbia University
% (c) 2020

\documentclass[12pt,letterpaper]{article}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{amscd}
\usepackage{enumerate}
\usepackage{fancyhdr}
\usepackage{mathrsfs}
\usepackage{bbm}
\usepackage{framed}
\usepackage{mdframed}
\usepackage{listings}
\usepackage{cancel}
\usepackage{mathtools}
\usepackage{verbatim}
\usepackage{enumitem}
\usepackage[letterpaper,voffset=-.5in,bmargin=3cm,footskip=1cm]{geometry}
\usepackage[colorlinks = true]{hyperref} 
\setlength{\parindent}{0.0in}
\setlength{\parskip}{0.1in}
\allowdisplaybreaks
\headheight 15pt
\headsep 10pt
\newcommand\N{\mathbb N}
\newcommand\Z{\mathbb Z}
\newcommand\R{\mathbb R}
\newcommand\Q{\mathbb Q}
\newcommand\lcm{\operatorname{lcm}}
\newcommand\setbuilder[2]{\ensuremath{\left\{#1\;\middle|\;#2\right\}}}
\newcommand\E{\operatorname{E}}
\newcommand\V{\operatorname{V}}
\newcommand\Pow{\ensuremath{\operatorname{\mathcal{P}}}}

\DeclarePairedDelimiter\ceil{\lceil}{\rceil}
\DeclarePairedDelimiter\floor{\lfloor}{\rfloor}
\newcommand\hint[1]{\textbf{Hint}: #1}
\newcommand\note[1]{\textbf{Note}: #1}

\lstset{
  basicstyle=\ttfamily,
  columns=fullflexible,
  frame=single,
  breaklines=true,
  postbreak=\mbox{\textcolor{red}{$\hookrightarrow$}},
}

\fancypagestyle{firstpagestyle} {
  \renewcommand{\headrulewidth}{0pt}
  \lhead{\textbf{ASTRUN 3646}}
  \rhead{\textbf{Rhessa Weber Langstaff, Ngan Bao, Alexandra Savino}}
  
}

\pagestyle{fancyplain}
\usepackage{tikz}

\begin{document}
  \thispagestyle{firstpagestyle}
  \begin{center}
    {\huge \textbf{Project Phase II Draft 1}}
  \end{center}

    
\subsection*{Main project topic}
The Robot Astronomer â€” We are building our own AI astronomer which determines the most 
searched objects in a given day, gets the coordinates of said object, AND decides what 
to observe beyond that. (The project will include an easily navigational and 
understandable website that consists of all relevant information.)

\subsection*{Background}
The field of astronomy has been revolutionized by advances in Artificial Intelligence 
(AI) and automation. These technologies have greatly improved our ability to collect 
and analyze vast amounts of astronomical data, enabling us to make significant 
discoveries about the universe.\\

One of the primary applications of AI and automation in astronomy is the collection 
of data. With the development of advanced telescopes and sensors, astronomers can now 
capture vast amounts of data about the universe. However, processing and analyzing 
this data manually can be a time-consuming and labor-intensive process. AI and automation 
have therefore been used to streamline the data collection process, allowing astronomers 
to gather more data in less time. In addition to collecting data, AI and automation have 
also been used to identify and select objects of interest for further observation. 
This is particularly important in astronomy, where there are billions of stars and 
other celestial objects to observe. By using AI algorithms to analyze the data collected 
by telescopes and sensors, astronomers can quickly identify objects that are most likely 
to yield valuable scientific insights.\\

Auto-selecting stellar objects to observe has become an important aspect of modern 
astronomy. AI and automation have made this process more efficient by enabling astronomers 
to quickly identify objects they are interested in, allowing them to focus their 
attention and resources on the most promising objects.\\

\subsection*{Data Collections and Methods}
\begin{enumerate}[leftmargin=*]
    \item Stage 1: Collect data from space news sites:  \texttt{website\_scraping.ipynb}:
        \begin{enumerate}
            \item [$-$] Use BeautifulSoup for website scraping
            \item [$-$] Websites: https://www.space.com/science-astronomy, \\
            https://www.sciencenews.org/topic/astronomy, \\ 
            https://www.nature.com/natastron/news-and-comment, \\ 
            https://phys.org/space-news/
            \item [$-$] Get headlines and write to \texttt{headlines.txt}
        \end{enumerate}
    \item Stage 2: Process keywords \texttt{keyword\_processing.ipynb}
        \begin{enumerate}
            \item [$-$] Use nltk for language and POS tagging
            \item [$-$] Find most popular topics \texttt{popular\_topics()}:
            \begin{enumerate}[leftmargin=*]
                \item[$\cdot$] Read \texttt{headlines.txt}
                \item[$\cdot$]Get nouns with nltk
                \item[$\cdot$]Write nouns in a dictionary and track count in headlines.
                \item[$\cdot$]Exclude generic words, websites, org names
                \item[$\cdot$]Get top 10 words with highest counts
                \item[$\cdot$]Write these words in \texttt{popular\_topics.txt} and 
                  their occurrences
            \end{enumerate}
        \end{enumerate}
    \item Stage 3: Find object names from popular topics list:
    \texttt{back\_search.ipynb}
        \begin{enumerate}
            \item [$-$] Use genism for summaries and object locating
            \begin{enumerate}[leftmargin=*]
                \item[$\cdot$] Search all headlines for top words
                \item[$\cdot$] Scrape articles from their corresponding links
                \item[$\cdot$] Create 40\% sized summaries of each article 
                \item[$\cdot$] Filter through summaries with a large 
                  list of object names accumulated from multiple databases
                \item[$\cdot$] Create list of final object names \texttt{data\final\_objects.txt}
            \end{enumerate}
        \end{enumerate}
    \item Stage 4: Search top topics in databases to find more information 
    about the objects, the coordinates and populate to html: \texttt{popular-object-to-html.py}:
        \begin{enumerate}
            \item [$-$] Reverse search using keywords on websites
            \item [$-$] Get exact objects names
            \item [$-$] Get objects' coordinates from databases, can feed object 
              name to $https://archive.stsci.edu/cgi-bin/dss\_form$, use Astropy
            \item [$-$] Determine if objects are observable, flag, and move to
              the next object if not observable
            \item [$-$] Use coordinates RA and Dec to get image 
              from $https://archive.stsci.edu/cgi-bin/dss\_form$
            \item [$-$] Save brief information about objects, coordinates, images and 
              related news/articles
        \end{enumerate}
    \item Stage 5: Create a user interface (website) that:
    \begin{enumerate}
        \item [$-$] Displays images of the most-searched objects (catalog and originally taken),
        general information about each object (ie. each's location in the sky), and information about
        how our original images will have been taken (ie. the time that an image was taken, etc)
        \item [$-$] Referential links to searched papers/articles
        \item [$-$] Includes a link to GitHub documentation
        \item [$-$] Includes an 'About Us' page, a page about the history of the stellarium telescope, 
          a project 'README' page, and possibly additional informational pages
    \end{enumerate}
\end{enumerate}

\subsection*{How the Program Runs}

Run \texttt{pip install -r requirements.txt} to install all the necessary packages.\\

Structures:
\begin{enumerate}
  \item [$-$] COMPONENTS: All python scripts
  \item [$-$] DATA: All data files
  \item [$-$] IMAGES: Where all images used for websites and images downloaded from stsci database are stored
  \item [$-$] PAGES: All html files
  \item [$-$] SCRIPTS: All javascript files
  \item [$-$] STYLES: All css files
  \item [$-$] UNIVERSAL: All common header and footer across all pages
\end{enumerate}
This section will describe the steps of how to run the program. We  decided that 
creating a \texttt{main.py} file that can be run each day and runs the files from 
each of the sections described above would be the best option to make this program 
as user-friendly as possible. This file calls functions from each back-end file, 
runs it, and moves on to the next step. We are currently working on creating the 
arguments needed for the command line option but the goal is that our website with 
the day's popular images would automatically open in the user's browser where they 
roam around on the interface.\\

The user interface starts with the title page (\texttt{title-page.html}) which, when 
clicked, transitions into the homepage or most popular object page,
\texttt{object-1-page.html}. Here the user can choose to click between the three most 
popular objects of the day using the center buttons or surf through our information 
pages using the drop across the menu in the top right corner which gives the user access 
to the About Us page, (\texttt{about-us.html}), the Final Paper page
 (\texttt{final-paper-page.html}) and References page (\texttt{ref-site-page.html}). \\

Documentation can be found on each page using the little GitHub button in the left bottom 
corner that brings the user straight to the public GitHub repository.

\subsection*{Project Goals}
The goal of this project is to automate the process of retrieving popular stellar objects 
from space news websites, analyzing them, and quickly determining the most popular ones to 
observe. We argue that because the popular objects in question are popular amongst
verifiable space news sources, they themselves are promising sources astronomically. 
The project aims to achieve this goal by utilizing advanced techniques in AI and 
automation.\\

The first objective of the project is to develop a web scraping tool that can 
crawl popular space news websites and retrieve articles related to stellar objects. 
The tool will then use natural language processing techniques to identify and extract 
the names of the stellar objects mentioned in the articles.\\

The second objective is to analyze the data collected by the web scraping tool 
to determine the most popular stellar objects among the articles retrieved. This 
will be achieved by using natural language processing to tag keywords mentioned 
in headlines to process the data and identify most mentioned objects in the articles.\\

The third objective is to search for the popular stellar objects identified in 
the second objective within the Space Telescope Science Institute (STScI) database 
using regular expression names. The tool will retrieve the  International 
Celestial Reference System (ICRS) coordinates of the objects, their images, 
and related articles/research papers from the STScI database.\\

The final objective is to present the data retrieved in a user-friendly interface 
that allows astronomers to quickly identify the most popular and promising stellar 
objects to observe. The interface will provide users with a dashboard that displays 
the ICRS coordinates, images, and related articles/research papers of the popular 
stellar objects.\\

Overall, the project aims to streamline the process of identifying and observing 
popular stellar objects by automating the data retrieval and analysis process. 
By achieving these objectives, the project will enable astronomers to make more 
efficient use of their time and resources, and increase the likelihood of making 
groundbreaking discoveries in the field of astronomy.\\

\end{document}

